{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import imageio\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from run_nerf_helpers import *\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from load_llff import load_llff_data\n",
    "from load_deepvoxels import load_dv_data\n",
    "from load_blender import load_blender_data\n",
    "from load_LINEMOD import load_LINEMOD_data\n",
    "import configargparse\n",
    "from run_nerf import batchify, run_network, batchify_rays, render, render_path, create_nerf, raw2outputs, render_rays, config_parser\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "np.random.seed(0)\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xqgao/anaconda3/envs/inr/lib/python3.12/site-packages/torch/__init__.py:1236: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:434.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded blender (138, 400, 400, 4) torch.Size([40, 4, 4]) [400, 400, np.float64(555.5555155968841)] /home/xqgao/2025/MIT/Datasets/NeRF/nerf_synthetic/lego\n",
      "Found ckpts ['null']\n",
      "Not ndc!\n",
      "RENDER ONLY\n",
      "test poses shape torch.Size([40, 4, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.004059314727783203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xqgao/anaconda3/envs/inr/lib/python3.12/site-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "  2%|▎         | 1/40 [00:06<04:05,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 400, 3]) torch.Size([400, 400])\n",
      "1 6.288769245147705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [00:12<03:53,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 6.023773431777954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3/40 [00:18<03:45,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 6.03666353225708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 4/40 [00:24<03:38,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 6.0545337200164795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 5/40 [00:30<03:32,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 6.06751275062561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 6/40 [00:36<03:26,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6.082669258117676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 7/40 [00:42<03:20,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 6.109835863113403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 8/40 [00:48<03:15,  6.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 6.124653100967407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 9/40 [00:54<03:09,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 6.136879205703735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 10/40 [01:01<03:03,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 6.139219045639038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 11/40 [01:07<02:57,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 6.154747009277344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 12/40 [01:13<02:51,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 6.1579673290252686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 13/40 [01:19<02:45,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 6.162424802780151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 14/40 [01:25<02:39,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 6.16940450668335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 15/40 [01:31<02:34,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 6.181149005889893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 16/40 [01:38<02:27,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 6.1707072257995605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 17/40 [01:44<02:21,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 6.168968677520752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 18/40 [01:50<02:15,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 6.1801393032073975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 19/40 [01:56<02:09,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 6.179092645645142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 20/40 [02:02<02:03,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 6.178071975708008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 21/40 [02:08<01:57,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 6.184280157089233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 22/40 [02:15<01:51,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 6.181585311889648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 23/40 [02:21<01:45,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 6.191661357879639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 24/40 [02:27<01:38,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 6.196957349777222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 25/40 [02:33<01:32,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 6.18497109413147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 26/40 [02:39<01:26,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 6.186652660369873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 27/40 [02:46<01:20,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 6.180799722671509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 28/40 [02:52<01:14,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 6.185983896255493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 29/40 [02:58<01:08,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 6.177866458892822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 30/40 [03:04<01:01,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 6.167341470718384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 31/40 [03:10<00:55,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 6.167719602584839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 32/40 [03:16<00:49,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 6.165492296218872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 33/40 [03:23<00:43,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 6.165848970413208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 34/40 [03:29<00:37,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 6.16896390914917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 35/40 [03:35<00:30,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 6.150846719741821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 36/40 [03:41<00:24,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 6.150238037109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 37/40 [03:47<00:18,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 6.1558897495269775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 38/40 [03:53<00:12,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 6.153788805007935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 39/40 [04:00<00:06,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 6.148360729217529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [04:06<00:00,  6.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done rendering /home/xqgao/2025/MIT/code/NeRF/nerf-pytorch-master/logs/blender_paper_lego/renderonly_path_000000\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "\n",
    "    parser = config_parser()\n",
    "    # args = parser.parse_args()\n",
    "    \n",
    "\n",
    "    # parser = config_parser()\n",
    "    args = parser.parse_args([\n",
    "        '--config', '/home/xqgao/2025/MIT/code/NeRF/nerf-pytorch-master/configs/lego.yaml'\n",
    "    ])\n",
    "\n",
    "    # Load data\n",
    "    K = None\n",
    "    if args.dataset_type == 'llff':\n",
    "        images, poses, bds, render_poses, i_test = load_llff_data(args.datadir, args.factor,\n",
    "                                                                  recenter=True, bd_factor=.75,\n",
    "                                                                  spherify=args.spherify)\n",
    "        hwf = poses[0,:3,-1]\n",
    "        poses = poses[:,:3,:4]\n",
    "        print('Loaded llff', images.shape, render_poses.shape, hwf, args.datadir)\n",
    "        if not isinstance(i_test, list):\n",
    "            i_test = [i_test]\n",
    "\n",
    "        if args.llffhold > 0:\n",
    "            print('Auto LLFF holdout,', args.llffhold)\n",
    "            i_test = np.arange(images.shape[0])[::args.llffhold]\n",
    "\n",
    "        i_val = i_test\n",
    "        i_train = np.array([i for i in np.arange(int(images.shape[0])) if\n",
    "                        (i not in i_test and i not in i_val)])\n",
    "\n",
    "        print('DEFINING BOUNDS')\n",
    "        if args.no_ndc:\n",
    "            near = np.ndarray.min(bds) * .9\n",
    "            far = np.ndarray.max(bds) * 1.\n",
    "            \n",
    "        else:\n",
    "            near = 0.\n",
    "            far = 1.\n",
    "        print('NEAR FAR', near, far)\n",
    "\n",
    "    elif args.dataset_type == 'blender':\n",
    "        images, poses, render_poses, hwf, i_split = load_blender_data(args.datadir, args.half_res, args.testskip)\n",
    "        print('Loaded blender', images.shape, render_poses.shape, hwf, args.datadir)\n",
    "        i_train, i_val, i_test = i_split\n",
    "\n",
    "        near = 2.\n",
    "        far = 6.\n",
    "\n",
    "        if args.white_bkgd:\n",
    "            images = images[...,:3]*images[...,-1:] + (1.-images[...,-1:])\n",
    "        else:\n",
    "            images = images[...,:3]\n",
    "\n",
    "    elif args.dataset_type == 'LINEMOD':\n",
    "        images, poses, render_poses, hwf, K, i_split, near, far = load_LINEMOD_data(args.datadir, args.half_res, args.testskip)\n",
    "        print(f'Loaded LINEMOD, images shape: {images.shape}, hwf: {hwf}, K: {K}')\n",
    "        print(f'[CHECK HERE] near: {near}, far: {far}.')\n",
    "        i_train, i_val, i_test = i_split\n",
    "\n",
    "        if args.white_bkgd:\n",
    "            images = images[...,:3]*images[...,-1:] + (1.-images[...,-1:])\n",
    "        else:\n",
    "            images = images[...,:3]\n",
    "\n",
    "    elif args.dataset_type == 'deepvoxels':\n",
    "\n",
    "        images, poses, render_poses, hwf, i_split = load_dv_data(scene=args.shape,\n",
    "                                                                 basedir=args.datadir,\n",
    "                                                                 testskip=args.testskip)\n",
    "\n",
    "        print('Loaded deepvoxels', images.shape, render_poses.shape, hwf, args.datadir)\n",
    "        i_train, i_val, i_test = i_split\n",
    "\n",
    "        hemi_R = np.mean(np.linalg.norm(poses[:,:3,-1], axis=-1))\n",
    "        near = hemi_R-1.\n",
    "        far = hemi_R+1.\n",
    "\n",
    "    else:\n",
    "        print('Unknown dataset type', args.dataset_type, 'exiting')\n",
    "        return\n",
    "\n",
    "    # Cast intrinsics to right types\n",
    "    H, W, focal = hwf\n",
    "    H, W = int(H), int(W)\n",
    "    hwf = [H, W, focal]\n",
    "\n",
    "    if K is None:\n",
    "        K = np.array([\n",
    "            [focal, 0, 0.5*W],\n",
    "            [0, focal, 0.5*H],\n",
    "            [0, 0, 1]\n",
    "        ])\n",
    "\n",
    "    if args.render_test:\n",
    "        render_poses = np.array(poses[i_test])\n",
    "\n",
    "    # Create log dir and copy the config file\n",
    "    basedir = args.basedir\n",
    "    expname = args.expname\n",
    "    os.makedirs(os.path.join(basedir, expname), exist_ok=True)\n",
    "    f = os.path.join(basedir, expname, 'args.txt')\n",
    "    with open(f, 'w') as file:\n",
    "        for arg in sorted(vars(args)):\n",
    "            attr = getattr(args, arg)\n",
    "            file.write('{} = {}\\n'.format(arg, attr))\n",
    "    if args.config is not None:\n",
    "        f = os.path.join(basedir, expname, 'config.txt')\n",
    "        with open(f, 'w') as file:\n",
    "            file.write(open(args.config, 'r').read())\n",
    "\n",
    "    # Create nerf model\n",
    "    render_kwargs_train, render_kwargs_test, start, grad_vars, optimizer = create_nerf(args)\n",
    "    global_step = start\n",
    "\n",
    "    bds_dict = {\n",
    "        'near' : near,\n",
    "        'far' : far,\n",
    "    }\n",
    "    render_kwargs_train.update(bds_dict)\n",
    "    render_kwargs_test.update(bds_dict)\n",
    "\n",
    "    # Move testing data to GPU\n",
    "    render_poses = torch.Tensor(render_poses).to(device)\n",
    "\n",
    "    # Short circuit if only rendering out from trained model\n",
    "    \n",
    "\n",
    "\n",
    "    print('RENDER ONLY')\n",
    "    with torch.no_grad():\n",
    "        if args.render_test:\n",
    "            # render_test switches to test poses\n",
    "            images = images[i_test]\n",
    "        else:\n",
    "            # Default is smoother render_poses path\n",
    "            images = None\n",
    "\n",
    "        testsavedir = os.path.join(basedir, expname, 'renderonly_{}_{:06d}'.format('test' if args.render_test else 'path', start))\n",
    "        os.makedirs(testsavedir, exist_ok=True)\n",
    "        print('test poses shape', render_poses.shape)\n",
    "\n",
    "        rgbs, _ = render_path(render_poses, hwf, K, args.chunk, render_kwargs_test, gt_imgs=images, savedir=testsavedir, render_factor=args.render_factor)\n",
    "        print('Done rendering', testsavedir)\n",
    "        imageio.mimwrite(os.path.join(testsavedir, 'video.mp4'), to8b(rgbs), fps=30, quality=8)\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
