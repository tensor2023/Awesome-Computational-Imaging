ä½ è¿™ä¸ªé—®é¢˜é—®å¾—éå¸¸å…³é”®ï¼æˆ‘ä»¬æ¥è¯¦ç»†è®²è®²ï¼š

---

### âœ… æ˜¯çš„ï¼Œ**DIP çš„è¡¨ç°**ä¼šå—åˆ°ç½‘ç»œç»“æ„çš„**ä¸¥é‡å½±å“**ã€‚

ğŸ’¡ **â€œä»ç½‘ç»œç»“æ„ä¸­è‡ªç„¶äº§ç”Ÿâ€**ï¼ŒæŒ‡çš„æ˜¯ï¼š
- å³ä½¿ç½‘ç»œæ˜¯**éšæœºåˆå§‹åŒ–**çš„ï¼Œä¹Ÿèƒ½é€šè¿‡ä¼˜åŒ–å‚æ•°ï¼ˆæ‹Ÿåˆä¸€å¼ å›¾åƒï¼‰è¡¨ç°å‡ºâ€œå›¾åƒå…ˆéªŒâ€çš„æ•ˆæœã€‚
- å› ä¸ºæŸäº›ç»“æ„ï¼ˆå¦‚å·ç§¯ã€UNetï¼‰**å¤©ç”Ÿåå¥½å¹³æ»‘ã€æœ‰çº¹ç†çš„å›¾åƒ**ï¼Œä¸å®¹æ˜“ç”Ÿæˆçº¯å™ªå£°ã€‚

æ‰€ä»¥ï¼š
> â— æ¢ä¸ªç½‘ç»œç»“æ„ï¼Œæ¯”å¦‚ç”¨å…¨è¿æ¥å±‚ï¼Œæ•ˆæœå°±å¯èƒ½å¾ˆå·®ã€‚

---

### âœ… â€œå®Œå…¨ä¸è®­ç»ƒâ€ â‰  â€œä¸ä¼˜åŒ–â€  
**â€œå®Œå…¨ä¸è®­ç»ƒâ€**æŒ‡çš„æ˜¯ï¼š
- ä¸ä½¿ç”¨**æ•°æ®é›†è¿›è¡Œç›‘ç£å­¦ä¹ **ï¼ˆæ²¡æœ‰æˆç™¾ä¸Šåƒå¼ å›¾åƒä½œä¸ºè®­ç»ƒé›†ï¼‰
- æ²¡æœ‰â€œè®­ç»ƒ + æµ‹è¯•â€åˆ†å‰²
- ç½‘ç»œçš„åˆå§‹åŒ–å‚æ•°ä¸æ˜¯ç»è¿‡è®­ç»ƒå¾—åˆ°çš„

ä½†æ˜¯ï¼DIP **ä¼šåšä¼˜åŒ–**ï¼Œä¹Ÿå°±æ˜¯ï¼š

```python
loss = loss_fn(output, y)
loss.backward()
optimizer.step()
```

ğŸ§  æ‰€ä»¥ï¼š
> âœ”ï¸ æœ‰ `.backward()`ï¼Œæœ‰ `optimizer.step()`ï¼Œä½†åªæ˜¯åœ¨**ä¸€å¼ å›¾åƒ**ä¸Šåšâ€œæ‹Ÿåˆâ€ï¼Œä¸æ˜¯é€šç”¨çš„è®­ç»ƒã€‚

---

### ğŸ§© DIP vs æ™®é€šè®­ç»ƒçš„åŒºåˆ«æ€»ç»“ï¼š

| æ¯”è¾ƒé¡¹ | DIP | å¸¸è§„ç¥ç»ç½‘ç»œè®­ç»ƒ |
|--------|-----|------------------|
| æ•°æ®é›† | âŒ åªç”¨ä¸€å¼ å›¾åƒ | âœ… å¤šå¼ å›¾åƒ |
| æ˜¯å¦è®­ç»ƒ | âŒ æ²¡æœ‰ç›‘ç£å­¦ä¹  | âœ… è¦è®­ç»ƒ |
| æ˜¯å¦ä¼˜åŒ–å‚æ•° | âœ… æ˜¯ | âœ… æ˜¯ |
| ä¼˜åŒ–ç›®æ ‡ | æ‹Ÿåˆä¸€å¼ é€€åŒ–å›¾åƒ | å­¦ä¹ é€šç”¨æ¨¡å‹ |
| .backward() | âœ… æœ‰ | âœ… æœ‰ |

---

### âœ… ä¸­æ–‡æ€»ç»“ï¼š
> DIP å¹¶ä¸æ˜¯â€œå®Œå…¨ä¸è®­ç»ƒå‚æ•°â€ï¼Œè€Œæ˜¯ä¸è®­ç»ƒä¸€ä¸ªé€šç”¨æ¨¡å‹ã€‚å®ƒæ˜¯åœ¨**æ¯å¼ å›¾åƒä¸Šå•ç‹¬æ‹Ÿåˆ**ï¼Œæ‰€ä»¥ç½‘ç»œç»“æ„çš„è®¾è®¡éå¸¸é‡è¦ï¼Œå½±å“å®ƒæ˜¯å¦èƒ½è‡ªç„¶ç”Ÿæˆâ€œçœ‹èµ·æ¥çœŸå®â€çš„å›¾åƒã€‚

### âœ… English summary:
> DIP doesn't train a generalizable model, but it does optimize the parameters for each image individually. Network architecture is crucial because the "prior" comes from the structural bias of the architecture.

---

å¦‚æœä½ æƒ³è¯•è¯•ç”¨ä¸åŒç»“æ„çš„ç½‘ç»œè·‘ DIPï¼Œæˆ‘å¯ä»¥ç»™ä½ ä¸€äº›ä»£ç ç¤ºä¾‹å¯¹æ¯”æ•ˆæœã€‚è¦å—ï¼ŸğŸ§ªğŸ”
