
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Pixel to Gaussian: Ultra-Fast Continuous Super-Resolution with 2D Gaussian Modeling &#8212; Awesome Computational Imaging</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapters/chapters/Chapter06_Pixel2Gaussian/pixel2gaussian';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../../intro.html">
  
  
  
  
  
  
    <p class="title logo__title">Awesome Computational Imaging</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../intro.html">
                    Awesome-Computational-Imaging
                </a>
            </li>
        </ul>
        
    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/chapters/chapters/Chapter06_Pixel2Gaussian/pixel2gaussian.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Pixel to Gaussian: Ultra-Fast Continuous Super-Resolution with 2D Gaussian Modeling</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#background">1. Background</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-core-idea">2. The Core Idea</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-not-directly-predict-gaussians-from-lr">Why not directly predict Gaussians from LR?</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#a-deep-gaussian-prior-dgp">a. <strong>Deep Gaussian Prior (DGP):</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#b-dgp-driven-covariance-weighting-ddcw">b. <strong>DGP-Driven Covariance Weighting (DDCW):</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#c-adaptive-position-drifting-apd">c. <strong>Adaptive Position Drifting (APD):</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#contributions">3. Contributions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">4. References</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-architecture-continuousgaussian-implementation-overview">Model Architecture: ContinuousGaussian (Implementation Overview)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-extraction">üîß 1. Feature Extraction</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#color-prediction-mlp">üü¢ 2. Color Prediction (MLP)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#covariance-estimation-via-deep-gaussian-prior-dgp">üü° 3. Covariance Estimation via Deep Gaussian Prior (DGP)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adaptive-position-drifting-apd">üî¥ 4. Adaptive Position Drifting (APD)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rendering-with-2d-gaussian-splatting">üéØ 5. Rendering with 2D Gaussian Splatting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">üìå Summary</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p><img alt="image.png" src="../../../_images/image7.png" /></p>
<section id="pixel-to-gaussian-ultra-fast-continuous-super-resolution-with-2d-gaussian-modeling">
<h1>Pixel to Gaussian: Ultra-Fast Continuous Super-Resolution with 2D Gaussian Modeling<a class="headerlink" href="#pixel-to-gaussian-ultra-fast-continuous-super-resolution-with-2d-gaussian-modeling" title="Link to this heading">#</a></h1>
<p><strong>Long Peng, Anran Wu, Wenbo Li, Peizhe Xia, Xueyuan Dai, Xinjie Zhang, Xin Di, Haoze Sun, Renjing Pei, Yang Wang, Yang Cao, Zheng-Jun Zha</strong><br />
Affiliations: USTC, Huawei Noah‚Äôs Ark Lab, HKUST, THU, etc.<br />
Published at: CVPR 2025 (arXiv:2503.06617v1)</p>
<hr class="docutils" />
<section id="background">
<h2>1. Background<a class="headerlink" href="#background" title="Link to this heading">#</a></h2>
<p>Super-resolution (SR) aims to recover a high-resolution (HR) image from its low-resolution (LR) counterpart. Traditional SR methods focus on fixed integer scales like √ó2, √ó3, or √ó4, which limits flexibility in real applications.</p>
<p>To solve this, <strong>Arbitrary-Scale Super-Resolution (ASSR)</strong> was proposed. A landmark method, <strong>LIIF</strong> [Chen et al., 2021], introduces <em>implicit neural representation (INR)</em> to map coordinates to RGB values via an MLP. Given any continuous coordinate $(x, y)$, the network outputs the corresponding color, enabling continuous upscaling.</p>
<p>However, such INR-based methods suffer from:</p>
<ul class="simple">
<li><p>Inefficiency: each pixel requires repeated querying and decoding.</p></li>
<li><p>Limited fidelity: coordinate-based MLPs struggle to capture high-frequency textures.</p></li>
<li><p>Complex pipeline: involves multiple upsampling-decoding stages.</p></li>
</ul>
<p>In essence, while INR methods can do continuous SR, they do so <strong>slowly</strong> and <strong>with limited detail reconstruction</strong>.</p>
</section>
<hr class="docutils" />
<section id="the-core-idea">
<h2>2. The Core Idea<a class="headerlink" href="#the-core-idea" title="Link to this heading">#</a></h2>
<p>This paper proposes a fundamentally new idea:<br />
Instead of <strong>learning a function to query pixels</strong>, learn to <strong>explicitly construct a continuous image field</strong>, represented by a set of 2D <strong>Gaussian kernels</strong>.</p>
<p>Each kernel is parameterized by its spatial position $\mu$, covariance matrix $\Sigma$, and RGB color $c_{rgb}$. The reconstructed image is the sum of $N$ such Gaussians:</p>
<p>$$
f_c(x, y) = \sum_{i=1}^N G_i(x, y)
$$</p>
<p>Each Gaussian kernel $G_i$ is defined as:</p>
<p>$$
G_i(x, y, c_{rgb}, \Sigma) = c_{rgb} \cdot \frac{1}{2\pi |\Sigma|} \exp \left( -\frac{1}{2} d^T \Sigma^{-1} d \right)
$$</p>
<p>where $d = \begin{bmatrix} x - \mu_x \ y - \mu_y \end{bmatrix}$.</p>
<p>The covariance matrix is:</p>
<p>$$
\Sigma = \begin{bmatrix}
\sigma_x^2 &amp; \rho \sigma_x \sigma_y \
\rho \sigma_x \sigma_y &amp; \sigma_y^2
\end{bmatrix}
$$</p>
<section id="why-not-directly-predict-gaussians-from-lr">
<h3>Why not directly predict Gaussians from LR?<a class="headerlink" href="#why-not-directly-predict-gaussians-from-lr" title="Link to this heading">#</a></h3>
<p>Directly learning these parameters is hard ‚Äî the space is sensitive and high-dimensional. Even small errors in $\mu$ or $\Sigma$ can lead to large perceptual distortions.</p>
<p>To address this, the authors propose:</p>
<section id="a-deep-gaussian-prior-dgp">
<h4>a. <strong>Deep Gaussian Prior (DGP):</strong><a class="headerlink" href="#a-deep-gaussian-prior-dgp" title="Link to this heading">#</a></h4>
<p>Analyze 40,000 natural images to uncover statistical priors on $\sigma_x^2$, $\sigma_y^2$, and $\rho$.<br />
Result: Most values fall in compact Gaussian-distributed ranges (e.g., $\sigma^2 \in [0, 2.4]$).</p>
</section>
<section id="b-dgp-driven-covariance-weighting-ddcw">
<h4>b. <strong>DGP-Driven Covariance Weighting (DDCW):</strong><a class="headerlink" href="#b-dgp-driven-covariance-weighting-ddcw" title="Link to this heading">#</a></h4>
<p>Instead of learning $\Sigma$ from scratch, learn weights to combine pre-defined covariances sampled from the DGP distribution:</p>
<p>$$
\sigma_{i,x}^2, \sigma_{i,y}^2 \sim P(\sigma^2), \quad \rho_i \sigma_{i,x} \sigma_{i,y} \sim P(\rho \sigma_x \sigma_y)
$$</p>
<p>Then construct a target kernel by weighted sum:</p>
<p>$$
G_{\text{target}} = \sum_{i=1}^N w_i \cdot G_i
$$</p>
</section>
<section id="c-adaptive-position-drifting-apd">
<h4>c. <strong>Adaptive Position Drifting (APD):</strong><a class="headerlink" href="#c-adaptive-position-drifting-apd" title="Link to this heading">#</a></h4>
<p>Learn position offsets $\Delta \mu$ from the LR image feature map, rather than fixing kernel centers:</p>
<p>$$
P_{\text{final}} = P_{\text{init}} + \tanh(\text{MLP}(F_{LR}))
$$</p>
<p>This helps concentrate Gaussians in textured regions.</p>
</section>
</section>
</section>
<hr class="docutils" />
<section id="contributions">
<h2>3. Contributions<a class="headerlink" href="#contributions" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Propose <strong>ContinuousSR</strong>, the first to reconstruct 2D continuous signals explicitly from LR images using 2D Gaussian splatting.</p></li>
<li><p>Discover <strong>Deep Gaussian Prior (DGP)</strong> and propose <strong>DGP-Driven Covariance Weighting (DDCW)</strong> to simplify optimization.</p></li>
<li><p>Introduce <strong>Adaptive Position Drifting (APD)</strong> to dynamically place kernels based on image content.</p></li>
<li><p>Achieve <strong>19.5√ó speedup</strong> and <strong>+0.9 dB PSNR gain</strong> over previous SOTA (e.g., CiaoSR, LIIF) on multiple benchmarks.</p></li>
</ul>
</section>
<hr class="docutils" />
<section id="references">
<h2>4. References<a class="headerlink" href="#references" title="Link to this heading">#</a></h2>
<p>[1] Chen et al. ‚ÄúLearning Continuous Image Representation with Local Implicit Image Function.‚Äù CVPR, 2021.<br />
[2] Peng et al. ‚ÄúPixel to Gaussian: Ultra-Fast Continuous Super-Resolution with 2D Gaussian Modeling.‚Äù CVPR, 2025.<br />
[3] Cao et al. ‚ÄúCiaoSR: Continuous Implicit Attention-in-Attention Network for ASSR.‚Äù CVPR, 2023.<br />
[4] Zhang et al. ‚ÄúGaussianImage: High-Fidelity 2D Gaussian Splatting for SR.‚Äù ECCV, 2024.</p>
<p>The training code has not been released yet; only the pre-trained model and the testing code have been provided for evaluation.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">argparse</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">partial</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">yaml</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">datasets</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">models</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">utils</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">make_coord</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">save_image</span>
<span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--input&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;/home/xqgao/2025/MIT/code/GS/ContinuousSR-main/butterflyx4.png&#39;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Input image file&#39;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--model&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;/home/xqgao/2025/MIT/code/GS/ContinuousSR-main/ContinuousSR.pth&#39;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Path to the model file&#39;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--scale&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;4,4&#39;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Scaling factors for the image (default: 4,4)&#39;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--output&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;/home/xqgao/2025/MIT/code/GS/ContinuousSR-main/output.png&#39;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Output image file&#39;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;--gpu&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s1">&#39;0&#39;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">&#39;GPU index to use (default: 0)&#39;</span><span class="p">)</span>
<span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">([])</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;CUDA_VISIBLE_DEVICES&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">gpu</span>

</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load image and model</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">input</span><span class="p">)</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s1">&#39;RGB&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">model_spec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">model</span><span class="p">)[</span><span class="s1">&#39;model&#39;</span><span class="p">]</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">model_spec</span><span class="p">,</span> <span class="n">load_sd</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="c1"># Prepare scales</span>
<span class="n">scales</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">)]</span>  <span class="c1"># you can add more scales</span>
<span class="n">titles</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Original&quot;</span><span class="p">,</span> <span class="s2">&quot;√ó2.5&quot;</span><span class="p">,</span> <span class="s2">&quot;√ó4&quot;</span><span class="p">,</span> <span class="s2">&quot;√ó6&quot;</span><span class="p">]</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Predict and store each scale result</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">scales</span><span class="p">:</span>
        <span class="n">scale_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">]]])</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">scale_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToPILImage</span><span class="p">()(</span><span class="n">pred</span><span class="p">))</span>

<span class="c1"># Also include original image for comparison</span>
<span class="n">original_img</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToPILImage</span><span class="p">()(</span><span class="n">img</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
<span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">original_img</span>  <span class="c1"># ensure original is first</span>

<span class="c1"># Plot all results</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">titles</span><span class="p">,</span> <span class="n">results</span><span class="p">)):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">scales</span><span class="p">),</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>/tmp/ipykernel_3534998/3970855738.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don&#39;t have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_spec = torch.load(args.model)[&#39;model&#39;]
</pre></div>
</div>
<p><img alt="png" src="../../../_images/pixel2gaussian_4_1.png" /></p>
</section>
<section id="model-architecture-continuousgaussian-implementation-overview">
<h2>Model Architecture: ContinuousGaussian (Implementation Overview)<a class="headerlink" href="#model-architecture-continuousgaussian-implementation-overview" title="Link to this heading">#</a></h2>
<p>In this section, we break down the architecture of <code class="docutils literal notranslate"><span class="pre">ContinuousGaussian</span></code>, the model used to implement the ContinuousSR framework proposed in <em>Pixel to Gaussian: Ultra-Fast Continuous Super-Resolution with 2D Gaussian Modeling (CVPR 2025)</em>.</p>
<p>This model transforms a low-resolution (LR) image into a continuous high-resolution (HR) signal using <strong>2D Gaussian kernels</strong>, as proposed in the Pixel-to-Gaussian paradigm.</p>
<hr class="docutils" />
<section id="feature-extraction">
<h3>üîß 1. Feature Extraction<a class="headerlink" href="#feature-extraction" title="Link to this heading">#</a></h3>
<p>The model begins with a CNN encoder (<code class="docutils literal notranslate"><span class="pre">self.encoder</span></code>) to extract low-resolution features from the input image $I_{LR}$. Then, a <code class="docutils literal notranslate"><span class="pre">PixelUnshuffle</span></code> operation increases the number of channels and prepares feature vectors for dense prediction. This gives us:</p>
<p>$$
F_{LR} = E(I_{LR})
$$</p>
<p>where $E(\cdot)$ is the encoder and $F_{LR}$ is the processed feature tensor.</p>
</section>
<hr class="docutils" />
<section id="color-prediction-mlp">
<h3>üü¢ 2. Color Prediction (MLP)<a class="headerlink" href="#color-prediction-mlp" title="Link to this heading">#</a></h3>
<p>A multilayer perceptron <code class="docutils literal notranslate"><span class="pre">self.mlp</span></code> predicts the RGB values of each 2D Gaussian kernel from the encoded features:</p>
<p>$$
c_{\text{rgb}} = \text{MLP}(F_{LR})
$$</p>
<p>This corresponds to the color component $c_{rgb}$ in the Gaussian kernel definition:</p>
<p>$$
G_i(x, y) = c_{rgb} \cdot \frac{1}{2\pi |\Sigma|} \exp \left( -\frac{1}{2} (d^\top \Sigma^{-1} d) \right)
$$</p>
</section>
<hr class="docutils" />
<section id="covariance-estimation-via-deep-gaussian-prior-dgp">
<h3>üü° 3. Covariance Estimation via Deep Gaussian Prior (DGP)<a class="headerlink" href="#covariance-estimation-via-deep-gaussian-prior-dgp" title="Link to this heading">#</a></h3>
<p>Instead of directly regressing the sensitive covariance matrix $\Sigma$, the model performs a <strong>learned soft combination</strong> of pre-sampled kernels from the <strong>Deep Gaussian Prior (DGP)</strong>.</p>
<ul class="simple">
<li><p>The dictionary <code class="docutils literal notranslate"><span class="pre">self.gau_dict</span></code> contains pre-sampled triplets of $(\sigma_x^2, \sigma_y^2, \rho)$.</p></li>
<li><p>A learned feature embedding is matched with a trainable set of Gaussian embeddings using:</p></li>
</ul>
<p>$$
G_{\text{target}} = \sum_{i=1}^N w_i \cdot G_i, \quad \text{where } w_i = \text{softmax}(\text{MLP}(F_{LR}))
$$</p>
<p>This is the <strong>DGP-Driven Covariance Weighting</strong> (DDCW) module described in the paper.</p>
</section>
<hr class="docutils" />
<section id="adaptive-position-drifting-apd">
<h3>üî¥ 4. Adaptive Position Drifting (APD)<a class="headerlink" href="#adaptive-position-drifting-apd" title="Link to this heading">#</a></h3>
<p>To accurately determine the spatial position $\mu$ of each Gaussian kernel, the model introduces <strong>Adaptive Position Drifting (APD)</strong>. This is a learned offset applied to the fixed LR pixel grid:</p>
<p>$$
\mu = \mu_{\text{init}} + \Delta\mu, \quad \Delta\mu = \tanh(\text{MLP}<em>{\text{offset}}(F</em>{LR}))
$$</p>
<p>This allows the network to place more kernels in texture-rich areas, improving spatial fidelity.</p>
</section>
<hr class="docutils" />
<section id="rendering-with-2d-gaussian-splatting">
<h3>üéØ 5. Rendering with 2D Gaussian Splatting<a class="headerlink" href="#rendering-with-2d-gaussian-splatting" title="Link to this heading">#</a></h3>
<p>Once the Gaussian parameters $(\mu, \Sigma, c_{rgb})$ are estimated, the model <strong>projects</strong> and <strong>rasterizes</strong> them into a 2D canvas at arbitrary resolution $(H, W)$ using Gaussian splatting:</p>
<ul class="simple">
<li><p>Project each Gaussian kernel into the HR grid.</p></li>
<li><p>Aggregate their contributions using rasterization.</p></li>
</ul>
<p>This yields the final continuous super-resolved image:</p>
<p>$$
I_{HR}(x, y) = \sum_i G_i(x, y)
$$</p>
<p>The rendering pipeline avoids time-consuming upsampling and decoding, achieving <strong>real-time speed</strong> and <strong>continuous zoom</strong>.</p>
</section>
<hr class="docutils" />
<section id="summary">
<h3>üìå Summary<a class="headerlink" href="#summary" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Module</p></th>
<th class="head"><p>Function</p></th>
<th class="head"><p>Paper Component</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">encoder</span></code></p></td>
<td><p>Feature extraction</p></td>
<td><p>$F_{LR} = E(I_{LR})$</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mlp</span></code></p></td>
<td><p>RGB prediction</p></td>
<td><p>$c_{rgb} = \text{MLP}(F)$</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mlp_vector</span></code> + <code class="docutils literal notranslate"><span class="pre">gau_dict</span></code></p></td>
<td><p>Covariance weighting</p></td>
<td><p>DGP-Driven Covariance Weighting</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mlp_offset</span></code></p></td>
<td><p>Position offset</p></td>
<td><p>Adaptive Position Drifting</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">project_gaussians_2d</span></code> + <code class="docutils literal notranslate"><span class="pre">rasterize_gaussians_sum</span></code></p></td>
<td><p>Rendering</p></td>
<td><p>2D Gaussian Splatting</p></td>
</tr>
</tbody>
</table>
</div>
<p>The entire model replaces pixel-wise MLP query (e.g., LIIF) with <strong>explicit Gaussian construction + fast rasterization</strong>, improving both performance and efficiency.</p>
<hr class="docutils" />
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapters/chapters/Chapter06_Pixel2Gaussian"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#background">1. Background</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-core-idea">2. The Core Idea</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-not-directly-predict-gaussians-from-lr">Why not directly predict Gaussians from LR?</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#a-deep-gaussian-prior-dgp">a. <strong>Deep Gaussian Prior (DGP):</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#b-dgp-driven-covariance-weighting-ddcw">b. <strong>DGP-Driven Covariance Weighting (DDCW):</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#c-adaptive-position-drifting-apd">c. <strong>Adaptive Position Drifting (APD):</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#contributions">3. Contributions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">4. References</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-architecture-continuousgaussian-implementation-overview">Model Architecture: ContinuousGaussian (Implementation Overview)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-extraction">üîß 1. Feature Extraction</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#color-prediction-mlp">üü¢ 2. Color Prediction (MLP)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#covariance-estimation-via-deep-gaussian-prior-dgp">üü° 3. Covariance Estimation via Deep Gaussian Prior (DGP)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#adaptive-position-drifting-apd">üî¥ 4. Adaptive Position Drifting (APD)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rendering-with-2d-gaussian-splatting">üéØ 5. Rendering with 2D Gaussian Splatting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">üìå Summary</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Xueqing Gao
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>